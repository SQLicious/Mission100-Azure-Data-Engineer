{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "6987a7a6-3052-4bf1-870d-06369bbbc824",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "<span style=\"color:orange\">\n",
    " <h2> Databricks-Assignment 1 (Basic Common Transformation)\n",
    "</span>\n",
    "  <h5>\n",
    "    <span style=\"color:red\">\n",
    "<b>Author: Deepak Goyal <br>\n",
    "   <a> Assignment completed by : Roopmathi Gunna </a><br>\n",
    "   written and executed on DBR 12.2 in DB Community edition\n",
    "</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "80f60633-144a-411f-83b7-bb20c09175de",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n |-- id: integer (nullable = true)\n |-- first_name: string (nullable = true)\n |-- last_name: string (nullable = true)\n |-- email: string (nullable = true)\n |-- gender: string (nullable = true)\n |-- salary: integer (nullable = true)\n |-- creationDate: timestamp (nullable = true)\n |-- bonus: double (nullable = true)\n\n+---+----------+---------+--------------------+------+------+-------------------+--------+\n| id|first_name|last_name|               email|gender|salary|       creationDate|   bonus|\n+---+----------+---------+--------------------+------+------+-------------------+--------+\n|  1|    Valene|   Ingley|vingley0@livejour...|Female| 44104|1957-09-09 16:44:40|    null|\n|  2|  Lynnelle|    Hurll| lhurll1@answers.com|Female|112411|1907-05-10 17:38:56|    null|\n|  3|   Miranda|    Train|   mtrain2@imgur.com|Female| 91073|1941-01-24 16:05:23|12875.54|\n|  4|    Dulsea|     Foss|dfoss3@dagondesig...|Female|193291|1942-05-09 20:59:39|    null|\n|  5|    Anatol|  Dunklee| adunklee4@google.de|  Male| 22175|1950-07-26 16:28:00| 1432.12|\n+---+----------+---------+--------------------+------+------+-------------------+--------+\nonly showing top 5 rows\n\n"
     ]
    }
   ],
   "source": [
    "#Load employee data into a Dataframe\n",
    "input = \"/FileStore/Azurelib files/EmployeeData_input.csv\"\n",
    "df = spark.read.csv(input,header = True, inferSchema = True)\n",
    "df.printSchema()\n",
    "df.show(5)\n",
    "from pyspark.sql.functions import *\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "5b3ac98b-ae08-42ca-83aa-2c68621fd1c3",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "<b> Q1. How many employees are there in the input file?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ab3fead4-1dbe-4381-8bdf-5cec62470790",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------+\n|Total_employees|\n+---------------+\n|           1000|\n+---------------+\n\n"
     ]
    }
   ],
   "source": [
    "# Write your code using the Spark Function\n",
    "tot_employees = df.count()\n",
    "print (tot_employees) \n",
    "\n",
    "#another approach \n",
    "from pyspark.sql.functions import count\n",
    "df.select(count(\"*\").alias(\"Total_employees\")).show()\n",
    "\n",
    "# seems we have some rows that have null value in id column "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "7ceaa11f-bcb6-4659-a6bc-d4c4983acfb2",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "<b> Q2. What is the average salary of all the employees?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7d8dccf8-21cf-4e27-9e29-6874cef7cc5b",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+\n|Average_Salary|\n+--------------+\n|     100011.38|\n+--------------+\n\n"
     ]
    }
   ],
   "source": [
    "# Write your code using the Spark Function\n",
    "\n",
    "avg_salary = df.select(round(avg(\"salary\"), 2).alias(\"Average_Salary\"))\n",
    "avg_salary.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "808bdc43-42d2-4945-9bf4-99ff444ee1fa",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "<b> Q3. How many male and female employees are there in the input file?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0d890aac-43dd-49fb-9ac2-999158e327c9",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-----+\n|Gender|Count|\n+------+-----+\n|Female|  501|\n|  Male|  471|\n+------+-----+\n\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .table-result-container {\n",
       "    max-height: 300px;\n",
       "    overflow: auto;\n",
       "  }\n",
       "  table, th, td {\n",
       "    border: 1px solid black;\n",
       "    border-collapse: collapse;\n",
       "  }\n",
       "  th, td {\n",
       "    padding: 5px;\n",
       "  }\n",
       "  th {\n",
       "    text-align: left;\n",
       "  }\n",
       "</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>Gender</th><th>Count</th></tr></thead><tbody><tr><td>Female</td><td>501</td></tr><tr><td>Male</td><td>471</td></tr></tbody></table></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "aggData": [],
       "aggError": "",
       "aggOverflow": false,
       "aggSchema": [],
       "aggSeriesLimitReached": false,
       "aggType": "",
       "arguments": {},
       "columnCustomDisplayInfos": {},
       "data": [
        [
         "Female",
         501
        ],
        [
         "Male",
         471
        ]
       ],
       "datasetInfos": [],
       "dbfsResultPath": null,
       "isJsonSchema": true,
       "metadata": {},
       "overflow": false,
       "plotOptions": {
        "customPlotOptions": {},
        "displayType": "table",
        "pivotAggregation": null,
        "pivotColumns": null,
        "xColumns": null,
        "yColumns": null
       },
       "removedWidgets": [],
       "schema": [
        {
         "metadata": "{}",
         "name": "Gender",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "Count",
         "type": "\"long\""
        }
       ],
       "type": "table"
      }
     },
     "output_type": "display_data"
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "Databricks visualization. Run in Databricks to view."
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1.subcommand+json": {
       "bindings": {},
       "collapsed": false,
       "command": "%python\n__backend_agg_display_orig = display\n__backend_agg_dfs = []\ndef __backend_agg_display_new(df):\n    __backend_agg_df_modules = [\"pandas.core.frame\", \"databricks.koalas.frame\", \"pyspark.sql.dataframe\", \"pyspark.pandas.frame\", \"pyspark.sql.connect.dataframe\"]\n    if (type(df).__module__ in __backend_agg_df_modules and type(df).__name__ == 'DataFrame') or isinstance(df, list):\n        __backend_agg_dfs.append(df)\n\ndisplay = __backend_agg_display_new\n\ndef __backend_agg_user_code_fn():\n    import base64\n    exec(base64.standard_b64decode(\"IyBXcml0ZSB5b3VyIGNvZGUgdXNpbmcgdGhlIFNwYXJrIEZ1bmN0aW9uCm1hbGVfZmVtYWxlX2NvdW50ID0gZGYuZ3JvdXBCeSgiR2VuZGVyIikuYWdnKGNvdW50KCIqIikuYWxpYXMoIkNvdW50IikpLmZpbHRlcihjb2woIkdlbmRlciIpLmlzTm90TnVsbCgpKQptYWxlX2ZlbWFsZV9jb3VudC5zaG93KCkKCiNmb3IgIGFuIGludGVyYWN0aXZlIGJhciB2aXogSSBkZWNpZGVkIHRvIGFsc28gdXNlIGRpcGxheQpkaXNwbGF5KG1hbGVfZmVtYWxlX2NvdW50KQojIFRoZXJlIGFyZSAyOCByb3dzIHdpdGggYSBudWxsIHZhbHVlIGZvciBHZW5kZXIgY29sdW1uLCB0aGF0cyB3aHkgSSBoYXZlIHVzZWQgZmlsdGVyLmlzTm90TnVsbCgp\").decode())\n\ntry:\n    # run user code\n    __backend_agg_user_code_fn()\n\n    #reset display function\n    display = __backend_agg_display_orig\n\n    if len(__backend_agg_dfs) > 0:\n        # create a temp view\n        if type(__backend_agg_dfs[0]).__module__ == \"databricks.koalas.frame\":\n            # koalas dataframe\n            __backend_agg_dfs[0].to_spark().createOrReplaceTempView(\"DatabricksView72d6ca6\")\n        elif type(__backend_agg_dfs[0]).__module__ == \"pandas.core.frame\" or isinstance(__backend_agg_dfs[0], list):\n            # pandas dataframe\n            spark.createDataFrame(__backend_agg_dfs[0]).createOrReplaceTempView(\"DatabricksView72d6ca6\")\n        else:\n            __backend_agg_dfs[0].createOrReplaceTempView(\"DatabricksView72d6ca6\")\n        #run backend agg\n        display(spark.sql(\"\"\"WITH q AS (select * from DatabricksView72d6ca6) SELECT `Gender`,SUM(`Count`) `column_cd36fcea2` FROM q GROUP BY `Gender`\"\"\"))\n    else:\n        displayHTML(\"dataframe no longer exists. If you're using dataframe.display(), use display(dataframe) instead.\")\n\n\nfinally:\n    spark.sql(\"drop view if exists DatabricksView72d6ca6\")\n    display = __backend_agg_display_orig\n    del __backend_agg_display_new\n    del __backend_agg_display_orig\n    del __backend_agg_dfs\n    del __backend_agg_user_code_fn\n\n",
       "commandTitle": "Distribution Pie chart",
       "commandType": "auto",
       "commandVersion": 0,
       "commentThread": [],
       "commentsVisible": false,
       "contentSha256Hex": null,
       "customPlotOptions": {
        "redashChart": [
         {
          "key": "type",
          "value": "CHART"
         },
         {
          "key": "options",
          "value": {
           "alignYAxesAtZero": true,
           "coefficient": 1,
           "columnConfigurationMap": {
            "x": {
             "column": "Gender",
             "id": "column_cd36fcea1"
            },
            "y": [
             {
              "column": "Count",
              "id": "column_cd36fcea2",
              "transform": "SUM"
             }
            ]
           },
           "dateTimeFormat": "DD/MM/YYYY HH:mm",
           "direction": {
            "type": "counterclockwise"
           },
           "error_y": {
            "type": "data",
            "visible": true
           },
           "globalSeriesType": "pie",
           "legend": {
            "traceorder": "normal"
           },
           "missingValuesAsZero": true,
           "numberFormat": "0,0.[00000]",
           "percentFormat": "0[.]00%",
           "series": {
            "error_y": {
             "type": "data",
             "visible": true
            },
            "stacking": null
           },
           "seriesOptions": {
            "column_cd36fcea2": {
             "name": "Count",
             "type": "pie",
             "yAxis": 0
            }
           },
           "showDataLabels": true,
           "sizemode": "diameter",
           "sortX": true,
           "sortY": true,
           "swappedAxes": false,
           "textFormat": "",
           "useAggregationsUi": true,
           "valuesOptions": {},
           "version": 2,
           "xAxis": {
            "labels": {
             "enabled": true
            },
            "type": "-"
           },
           "yAxis": [
            {
             "type": "-"
            },
            {
             "opposite": true,
             "type": "-"
            }
           ]
          }
         }
        ]
       },
       "datasetPreviewNameToCmdIdMap": {},
       "diffDeletes": [],
       "diffInserts": [],
       "displayType": "redashChart",
       "error": null,
       "errorDetails": null,
       "errorSummary": null,
       "errorTraceType": null,
       "finishTime": 0,
       "globalVars": {},
       "guid": "",
       "height": "208",
       "hideCommandCode": false,
       "hideCommandResult": false,
       "iPythonMetadata": null,
       "inputWidgets": {},
       "isLockedInExamMode": false,
       "latestUser": "a user",
       "latestUserId": null,
       "listResultMetadata": null,
       "metadata": {},
       "nuid": "a61cb868-dc24-462d-8349-c341e8f6b483",
       "origId": 0,
       "parentHierarchy": [],
       "pivotAggregation": null,
       "pivotColumns": null,
       "position": 8.0,
       "resultDbfsErrorMessage": null,
       "resultDbfsStatus": "INLINED_IN_TREE",
       "results": null,
       "showCommandTitle": false,
       "startTime": 0,
       "state": "input",
       "streamStates": {},
       "subcommandOptions": {
        "queryPlan": {
         "groups": [
          {
           "column": "Gender",
           "type": "column"
          }
         ],
         "selects": [
          {
           "column": "Gender",
           "type": "column"
          },
          {
           "alias": "column_cd36fcea2",
           "args": [
            {
             "column": "Count",
             "type": "column"
            }
           ],
           "function": "SUM",
           "type": "function"
          }
         ]
        }
       },
       "submitTime": 0,
       "subtype": "tableResultSubCmd.visualization",
       "tableResultIndex": 0,
       "useConsistentColors": false,
       "version": "CommandV1",
       "width": "835",
       "workflows": [],
       "xColumns": null,
       "yColumns": null
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Write your code using the Spark Function\n",
    "male_female_count = df.groupBy(\"Gender\").agg(count(\"*\").alias(\"Count\")).filter(col(\"Gender\").isNotNull())\n",
    "male_female_count.show()\n",
    "\n",
    "# For an interactive bar viz I decided to also use diplay\n",
    "display(male_female_count)\n",
    "# There are 28 rows with a null value for Gender column, thats why I have used filter.isNotNull()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "a5e18b7e-62b5-4410-b160-18f25ae651a2",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "<b> Q4. Who is the employee with the highest salary?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "947dd3b0-5b8d-4535-a115-0f459ae8f1ab",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The employee with the highest salary is Alfonso Hanbridge with a salary of 199846\n"
     ]
    }
   ],
   "source": [
    "# Write your code using the Spark Function\n",
    "from pyspark.sql.functions import col\n",
    "\n",
    "# Find the employee with the highest salary\n",
    "highest_salary_employee = df.orderBy(col(\"salary\").desc()).limit(1).select(\n",
    "    \"first_name\",\n",
    "    \"last_name\",\n",
    "    \"salary\"\n",
    ").first()\n",
    "\n",
    "# Prints the result\n",
    "print(f\"The employee with the highest salary is {highest_salary_employee['first_name']} {highest_salary_employee['last_name']} with a salary of {highest_salary_employee['salary']}\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "a481d489-9076-491d-9413-afcb2f9bbb1a",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "<b> Q5. What is the total bonus amount paid to all the employees?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "546e94d4-e4f9-4713-bf37-79b5c9be164c",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .table-result-container {\n",
       "    max-height: 300px;\n",
       "    overflow: auto;\n",
       "  }\n",
       "  table, th, td {\n",
       "    border: 1px solid black;\n",
       "    border-collapse: collapse;\n",
       "  }\n",
       "  th, td {\n",
       "    padding: 5px;\n",
       "  }\n",
       "  th {\n",
       "    text-align: left;\n",
       "  }\n",
       "</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>Total_Bonus_Paid</th></tr></thead><tbody><tr><td>4.25048123E7</td></tr></tbody></table></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "aggData": [],
       "aggError": "",
       "aggOverflow": false,
       "aggSchema": [],
       "aggSeriesLimitReached": false,
       "aggType": "",
       "arguments": {},
       "columnCustomDisplayInfos": {},
       "data": [
        [
         4.25048123E7
        ]
       ],
       "datasetInfos": [],
       "dbfsResultPath": null,
       "isJsonSchema": true,
       "metadata": {},
       "overflow": false,
       "plotOptions": {
        "customPlotOptions": {},
        "displayType": "table",
        "pivotAggregation": null,
        "pivotColumns": null,
        "xColumns": null,
        "yColumns": null
       },
       "removedWidgets": [],
       "schema": [
        {
         "metadata": "{}",
         "name": "Total_Bonus_Paid",
         "type": "\"double\""
        }
       ],
       "type": "table"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Write your code using the Spark Function\n",
    "from pyspark.sql.functions import sum\n",
    "df.select(round(sum(\"Bonus\"), 2).alias(\"Total_Bonus_Paid\")).display()\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "4a0f2ec1-08df-4ebf-937d-f9917e196791",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "\n",
    "<b> Q6. How many employees were hired in the year 2020?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "65dbcf66-0cea-4387-aa8b-60a88e540f8e",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of employees hired in 2020: 7\n"
     ]
    }
   ],
   "source": [
    "# Write your code using the Spark Function\n",
    "from pyspark.sql.functions import year\n",
    "\n",
    "df_2020 = df.filter(year(\"creationDate\") == 2020)\n",
    "total_employees_2020 = df_2020.count()\n",
    "print(\"Number of employees hired in 2020:\", total_employees_2020)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "1119178d-1eb5-4308-afa1-4024d6c9e369",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    " \n",
    "<b> Q7. Who are the top 5 employees with the highest salaries?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "63bddabe-f12c-4579-9f2d-e0cfe8e79022",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+------+\n|Employee Name    |Salary|\n+-----------------+------+\n|Alfonso Hanbridge|199846|\n|Dermot Letchford |199484|\n|Jennee Ballingal |198873|\n|Griswold Kocher  |198688|\n|Baryram Whitham  |198672|\n+-----------------+------+\n\n+-----------------+------+\n|    Employee Name|salary|\n+-----------------+------+\n|Alfonso Hanbridge|199846|\n| Dermot Letchford|199484|\n| Jennee Ballingal|198873|\n|  Griswold Kocher|198688|\n|  Baryram Whitham|198672|\n+-----------------+------+\n\n"
     ]
    }
   ],
   "source": [
    "# Write your code using the Spark Function\n",
    "from pyspark.sql.functions import concat, col, desc\n",
    "top_5_salaries = df.orderBy(desc(\"salary\")).limit(5).select(concat(col(\"first_name\"), lit(\" \"), col(\"last_name\")).alias(\"Employee Name\"), \"Salary\")\n",
    "top_5_salaries.show(truncate=False)\n",
    "\n",
    "#another approach\n",
    "\n",
    "top_5_salaries2 = df.select(concat(col(\"first_name\"),lit(\" \"),col(\"last_name\")).alias(\"Employee Name\"), \"salary\").orderBy(desc(\"salary\")).limit(5)\n",
    "top_5_salaries2.show() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "a86448f9-436d-42c7-b889-52015d495ed9",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "<b> Q8. What is the total salary paid to all male employees?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "dc23260b-46d1-4f02-8c4a-a8a8c85e926b",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total salary paid to male employees: 44253777\nTotal salary paid to male employees: 44253777\n"
     ]
    }
   ],
   "source": [
    "# Write your code using the Spark Function\n",
    "\n",
    "total_salary_male = df.filter(df.gender == 'Male').agg(sum(\"salary\").alias(\"total_salary_male\")).collect()[0][\"total_salary_male\"]\n",
    "print(\"Total salary paid to male employees:\", total_salary_male)\n",
    "\n",
    "#another approach using first()\n",
    "total_salary_male = df.filter(df.gender == 'Male').agg(sum(\"salary\").alias(\"total_salary_male\")).first()[\"total_salary_male\"]\n",
    "print(\"Total salary paid to male employees:\", total_salary_male)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "f884bb3b-36a4-4ef9-9a89-634eff8ee781",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "\n",
    "<b> Q9. Who is the employee with the highest bonus amount?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "297aa8ea-7ffa-4db0-90b3-ad73ecb512bb",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------+--------+\n|  Employee Name|   bonus|\n+---------------+--------+\n|Franni Chessell|99993.16|\n+---------------+--------+\n\n"
     ]
    }
   ],
   "source": [
    "# Write your code using the Spark Function# Write your code using the Spark Function\n",
    "highest_bonus_employee = (df.orderBy(desc(\"bonus\"))\n",
    "                          .limit(1)\n",
    "                          .select(concat(col(\"first_name\"), lit(\" \"), col(\"last_name\")).alias(\"Employee Name\"), \"bonus\"))\n",
    "\n",
    "highest_bonus_employee.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "3c22077b-bf59-4c3d-bc9e-fca18a0873c2",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "\n",
    "<b> Q10. What is the earliest creation date of any employee in the input file?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8de25cdb-8bee-4652-bebb-73a9549771ab",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Earliest creation date of any employee: 1900-07-08\n"
     ]
    }
   ],
   "source": [
    "# Write your code using the Spark Function\n",
    "from pyspark.sql.functions import min\n",
    "\n",
    "earliest_creation_date = df.agg(min(\"creationDate\").cast(\"date\").alias(\"earliest_creation_date\")).collect()[0][\"earliest_creation_date\"]\n",
    "print(\"Earliest creation date of any employee:\", (earliest_creation_date))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "7a6d437e-7233-44c7-93be-c3f86dfcd55c",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "\n",
    "<b> Q11. How many employees have a salary greater than 100,000?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1befcd43-2d94-4a98-a9d6-660c8f301948",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of employees with salary greater than 100,000: 480\n"
     ]
    }
   ],
   "source": [
    "# Write your code using the Spark Function\n",
    "\n",
    "high_salary_count = df.filter(df.salary > 100000).count()\n",
    "print(\"Number of employees with salary greater than 100,000:\", high_salary_count)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "315bf294-cbea-4284-be44-57d5132069f7",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "\n",
    "<b> Q12.  Who is the female employee with the highest salary?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "88e1a535-bf47-4ae0-8306-4083a68a2b85",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+---------+------+\n|first_name|last_name|salary|\n+----------+---------+------+\n|    Jennee|Ballingal|198873|\n+----------+---------+------+\n\n"
     ]
    }
   ],
   "source": [
    "# Write your code using the Spark Function\n",
    "\n",
    "highest_salary_female = df.filter(df.gender == 'Female').orderBy(desc(\"salary\")).limit(1).select(\"first_name\",\"last_name\",\"salary\")\n",
    "highest_salary_female.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "9b87cf7d-fde1-44f0-98c5-e84e320677c7",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "\n",
    "<b> Q13. What is the total bonus amount paid to female employees?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0e790a6b-6394-4ba0-90e2-37141ae90d1f",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total bonus amount paid to female employees: 21323153.59\n"
     ]
    }
   ],
   "source": [
    "# Write your code using the Spark Function\n",
    "\n",
    "total_bonus_female = df.filter(df.gender == 'Female').agg(sum(\"bonus\").alias(\"total_bonus_female\")).collect()[0][\"total_bonus_female\"]\n",
    "print(\"Total bonus amount paid to female employees:\", total_bonus_female)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "48c93dbe-67e5-460e-bab0-804b533ff977",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "\n",
    "<b> Q14. How many employees have a salary between 50,000 and 75,000?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "847bc2e8-bb32-48aa-8fa6-2ab8f55cea80",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of employees with salary between 50,000 and 75,000: 117\n"
     ]
    }
   ],
   "source": [
    "# Write your code using the Spark Function\n",
    "\n",
    "salary_range_count = df.filter((df.salary >= 50000) & (df.salary <= 75000)).count()\n",
    "print(\"Number of employees with salary between 50,000 and 75,000:\", salary_range_count)\n",
    "# This approach is faster 0.53 seconds execution time \n",
    "\n",
    "#another approach using between()\n",
    "\n",
    "salary_range_count = df.filter(col(\"salary\").between(50000, 75000)).count()\n",
    "print(\"Number of employees with salary between 50,000 and 75,000:\", salary_range_count)\n",
    "# This took 0.69 seconds\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "d5e9e2a9-4133-407e-bc52-c332538b3a1b",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "\n",
    "<b> Q15. Who are the top 10 employees with the highest bonuses?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f67bd07c-76c9-44d1-9a64-1d7db068fc7e",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .table-result-container {\n",
       "    max-height: 300px;\n",
       "    overflow: auto;\n",
       "  }\n",
       "  table, th, td {\n",
       "    border: 1px solid black;\n",
       "    border-collapse: collapse;\n",
       "  }\n",
       "  th, td {\n",
       "    padding: 5px;\n",
       "  }\n",
       "  th {\n",
       "    text-align: left;\n",
       "  }\n",
       "</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>first_name</th><th>last_name</th><th>bonus</th></tr></thead><tbody><tr><td>Franni</td><td>Chessell</td><td>99993.16</td></tr><tr><td>Asher</td><td>Dupoy</td><td>99985.66</td></tr><tr><td>Lovell</td><td>Ingall</td><td>99932.43</td></tr><tr><td>Sullivan</td><td>Gyenes</td><td>99845.6</td></tr><tr><td>Jessie</td><td>Grgic</td><td>99650.89</td></tr><tr><td>Nicol</td><td>Bruton</td><td>99581.27</td></tr><tr><td>Nonah</td><td>Tompkiss</td><td>99046.27</td></tr><tr><td>Andy</td><td>Morch</td><td>99033.16</td></tr><tr><td>Swen</td><td>Hinrichsen</td><td>98721.92</td></tr><tr><td>Dorotea</td><td>Kynan</td><td>98639.27</td></tr></tbody></table></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "aggData": [],
       "aggError": "",
       "aggOverflow": false,
       "aggSchema": [],
       "aggSeriesLimitReached": false,
       "aggType": "",
       "arguments": {},
       "columnCustomDisplayInfos": {},
       "data": [
        [
         "Franni",
         "Chessell",
         99993.16
        ],
        [
         "Asher",
         "Dupoy",
         99985.66
        ],
        [
         "Lovell",
         "Ingall",
         99932.43
        ],
        [
         "Sullivan",
         "Gyenes",
         99845.6
        ],
        [
         "Jessie",
         "Grgic",
         99650.89
        ],
        [
         "Nicol",
         "Bruton",
         99581.27
        ],
        [
         "Nonah",
         "Tompkiss",
         99046.27
        ],
        [
         "Andy",
         "Morch",
         99033.16
        ],
        [
         "Swen",
         "Hinrichsen",
         98721.92
        ],
        [
         "Dorotea",
         "Kynan",
         98639.27
        ]
       ],
       "datasetInfos": [],
       "dbfsResultPath": null,
       "isJsonSchema": true,
       "metadata": {},
       "overflow": false,
       "plotOptions": {
        "customPlotOptions": {},
        "displayType": "table",
        "pivotAggregation": null,
        "pivotColumns": null,
        "xColumns": null,
        "yColumns": null
       },
       "removedWidgets": [],
       "schema": [
        {
         "metadata": "{}",
         "name": "first_name",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "last_name",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "bonus",
         "type": "\"double\""
        }
       ],
       "type": "table"
      }
     },
     "output_type": "display_data"
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "Databricks visualization. Run in Databricks to view."
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1.subcommand+json": {
       "bindings": {},
       "collapsed": false,
       "command": "%python\n__backend_agg_display_orig = display\n__backend_agg_dfs = []\ndef __backend_agg_display_new(df):\n    __backend_agg_df_modules = [\"pandas.core.frame\", \"databricks.koalas.frame\", \"pyspark.sql.dataframe\", \"pyspark.pandas.frame\", \"pyspark.sql.connect.dataframe\"]\n    if (type(df).__module__ in __backend_agg_df_modules and type(df).__name__ == 'DataFrame') or isinstance(df, list):\n        __backend_agg_dfs.append(df)\n\ndisplay = __backend_agg_display_new\n\ndef __backend_agg_user_code_fn():\n    import base64\n    exec(base64.standard_b64decode(\"IyBXcml0ZSB5b3VyIGNvZGUgdXNpbmcgdGhlIFNwYXJrIEZ1bmN0aW9uCgpmcm9tIHB5c3Bhcmsuc3FsLmZ1bmN0aW9ucyBpbXBvcnQgZGVzYwp0b3BfMTBfYm9udXNlcyA9IGRmLnNlbGVjdCgiZmlyc3RfbmFtZSIsICJsYXN0X25hbWUiLCAiYm9udXMiKS5vcmRlckJ5KGRlc2MoImJvbnVzIikpLmxpbWl0KDEwKQp0b3BfMTBfYm9udXNlcy5kaXNwbGF5KCk=\").decode())\n\ntry:\n    # run user code\n    __backend_agg_user_code_fn()\n\n    #reset display function\n    display = __backend_agg_display_orig\n\n    if len(__backend_agg_dfs) > 0:\n        # create a temp view\n        if type(__backend_agg_dfs[0]).__module__ == \"databricks.koalas.frame\":\n            # koalas dataframe\n            __backend_agg_dfs[0].to_spark().createOrReplaceTempView(\"DatabricksView0f2d9cb\")\n        elif type(__backend_agg_dfs[0]).__module__ == \"pandas.core.frame\" or isinstance(__backend_agg_dfs[0], list):\n            # pandas dataframe\n            spark.createDataFrame(__backend_agg_dfs[0]).createOrReplaceTempView(\"DatabricksView0f2d9cb\")\n        else:\n            __backend_agg_dfs[0].createOrReplaceTempView(\"DatabricksView0f2d9cb\")\n        #run backend agg\n        display(spark.sql(\"\"\"WITH q AS (select * from DatabricksView0f2d9cb) SELECT `first_name`,`first_name`,SUM(`bonus`) `column_cd36fcea5` FROM q GROUP BY `first_name`\"\"\"))\n    else:\n        displayHTML(\"dataframe no longer exists. If you're using dataframe.display(), use display(dataframe) instead.\")\n\n\nfinally:\n    spark.sql(\"drop view if exists DatabricksView0f2d9cb\")\n    display = __backend_agg_display_orig\n    del __backend_agg_display_new\n    del __backend_agg_display_orig\n    del __backend_agg_dfs\n    del __backend_agg_user_code_fn\n\n",
       "commandTitle": "Top 10 Employees by Bonus",
       "commandType": "auto",
       "commandVersion": 0,
       "commentThread": [],
       "commentsVisible": false,
       "contentSha256Hex": null,
       "customPlotOptions": {
        "redashChart": [
         {
          "key": "type",
          "value": "CHART"
         },
         {
          "key": "options",
          "value": {
           "alignYAxesAtZero": true,
           "coefficient": 1,
           "columnConfigurationMap": {
            "series": {
             "column": "first_name",
             "id": "column_cd36fcea10"
            },
            "x": {
             "column": "first_name",
             "id": "column_cd36fcea8"
            },
            "y": [
             {
              "column": "bonus",
              "id": "column_cd36fcea5",
              "transform": "SUM"
             }
            ]
           },
           "dateTimeFormat": "DD/MM/YYYY HH:mm",
           "direction": {
            "type": "counterclockwise"
           },
           "error_y": {
            "type": "data",
            "visible": true
           },
           "globalSeriesType": "column",
           "isAggregationOn": true,
           "legend": {
            "traceorder": "normal"
           },
           "missingValuesAsZero": true,
           "numberFormat": "0,0.[00000]",
           "percentFormat": "0[.]00%",
           "series": {
            "error_y": {
             "type": "data",
             "visible": true
            },
            "stacking": "stack"
           },
           "seriesOptions": {
            "Andy": {
             "color": "#000000"
            },
            "column_cd36fcea5": {
             "name": "bonus",
             "type": "column",
             "yAxis": 0
            }
           },
           "showDataLabels": true,
           "sizemode": "diameter",
           "sortX": false,
           "sortY": true,
           "swappedAxes": true,
           "textFormat": "",
           "useAggregationsUi": true,
           "valuesOptions": {},
           "version": 2,
           "xAxis": {
            "labels": {
             "enabled": true
            },
            "type": "-"
           },
           "yAxis": [
            {
             "type": "-"
            },
            {
             "opposite": true,
             "type": "-"
            }
           ]
          }
         }
        ]
       },
       "datasetPreviewNameToCmdIdMap": {},
       "diffDeletes": [],
       "diffInserts": [],
       "displayType": "redashChart",
       "error": null,
       "errorDetails": null,
       "errorSummary": null,
       "errorTraceType": null,
       "finishTime": 0,
       "globalVars": {},
       "guid": "",
       "height": "auto",
       "hideCommandCode": false,
       "hideCommandResult": false,
       "iPythonMetadata": null,
       "inputWidgets": {},
       "isLockedInExamMode": false,
       "latestUser": "a user",
       "latestUserId": null,
       "listResultMetadata": null,
       "metadata": {},
       "nuid": "e67db6b0-8803-4657-a8f7-bce0c691a3e5",
       "origId": 0,
       "parentHierarchy": [],
       "pivotAggregation": null,
       "pivotColumns": null,
       "position": 32.0,
       "resultDbfsErrorMessage": null,
       "resultDbfsStatus": "INLINED_IN_TREE",
       "results": null,
       "showCommandTitle": false,
       "startTime": 0,
       "state": "input",
       "streamStates": {},
       "subcommandOptions": {
        "queryPlan": {
         "groups": [
          {
           "column": "first_name",
           "type": "column"
          },
          {
           "column": "first_name",
           "type": "column"
          }
         ],
         "selects": [
          {
           "column": "first_name",
           "type": "column"
          },
          {
           "column": "first_name",
           "type": "column"
          },
          {
           "alias": "column_cd36fcea5",
           "args": [
            {
             "column": "bonus",
             "type": "column"
            }
           ],
           "function": "SUM",
           "type": "function"
          }
         ]
        }
       },
       "submitTime": 0,
       "subtype": "tableResultSubCmd.visualization",
       "tableResultIndex": 0,
       "useConsistentColors": false,
       "version": "CommandV1",
       "width": "auto",
       "workflows": [],
       "xColumns": null,
       "yColumns": null
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Write your code using the Spark Function\n",
    "\n",
    "from pyspark.sql.functions import desc\n",
    "top_10_bonuses = df.select(\"first_name\", \"last_name\", \"bonus\").orderBy(desc(\"bonus\")).limit(10)\n",
    "top_10_bonuses.display()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "625e6480-0d48-428e-8bc5-23c64431af3d",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "\n",
    "<b> Q16. What is the latest creation date of any employee in the input file?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3296515c-2b05-4f9d-96c9-c9ea595044d4",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Latest creation date of any employee: 2023-03-24\n"
     ]
    }
   ],
   "source": [
    "# Write your code using the Spark Function\n",
    "\n",
    "latest_creation_date = df.agg(max(\"creationdate\").cast(\"date\").alias(\"latest_creation_date\")).collect()[0][\"latest_creation_date\"]\n",
    "print(\"Latest creation date of any employee:\", latest_creation_date)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "8b3c7eb8-65ec-47d1-94e9-80d9e4bc5f1c",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "\n",
    "<b> Q17. How many employees have a salary less than 50,000?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f82b5d00-7e44-4076-8080-826d0c11ffb9",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of employees with salary less than 50,000: 234\n"
     ]
    }
   ],
   "source": [
    "# Write your code using the Spark Function\n",
    "\n",
    "low_salary_count = df.filter(df.salary < 50000).count()\n",
    "print(\"Number of employees with salary less than 50,000:\", low_salary_count)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "31cc824e-183d-4cf1-ad6b-71126c3fa92e",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "\n",
    "<b> Q18. Who are the top 3 employees with the lowest salaries?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c36e0b45-f426-4870-bb83-8200e4491f43",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+----------+----------+--------------------+------+------+-------------------+--------+\n| id|first_name| last_name|               email|gender|salary|       creationDate|   bonus|\n+---+----------+----------+--------------------+------+------+-------------------+--------+\n|809|  Hercules|Pollington|hpollingtonmg@chi...|  Male|   109|1936-08-10 16:43:14| 57493.2|\n|381|     Olwen| O'Scanlon| ooscanlonak@usa.gov|Female|   184|2017-10-11 06:21:17|22415.01|\n|542| Heriberto|      null| hsurmeyersf1@un.org|  Male|   479|               null|51871.41|\n+---+----------+----------+--------------------+------+------+-------------------+--------+\n\n"
     ]
    }
   ],
   "source": [
    "# Write your code using the Spark Function\n",
    "\n",
    "top_3_lowest_salaries = df.filter(col(\"salary\").isNotNull()).orderBy(\"salary\").limit(3)\n",
    "top_3_lowest_salaries.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "d2a0ab65-4e44-4edd-8781-3c2d9723c9fd",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "\n",
    "<b> Q19. What is the average bonus amount paid to all employees?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d697b9a0-d6e2-425b-a66b-7ee96e56f7f2",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average bonus amount paid to all employees: 50965.00275779381\n"
     ]
    }
   ],
   "source": [
    "# Write your code using the Spark Function\n",
    "# Assuming there is a 'bonus' column in your DataFrame\n",
    "average_bonus = df.agg(avg(\"bonus\").alias(\"average_bonus\")).collect()[0][\"average_bonus\"]\n",
    "print(\"Average bonus amount paid to all employees:\", average_bonus)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "ec198c70-feec-41b0-8c9d-510bf76d87ef",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "\n",
    "<b> Q20. How many employees have a bonus greater than their salary?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b484f9ac-b724-4f7a-975f-cebe0fd73201",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of employees with a bonus greater than their salary: 194\n"
     ]
    }
   ],
   "source": [
    "# Write your code using the Spark Function\n",
    "# Assuming there are 'bonus' and 'salary' columns in your DataFrame\n",
    "bonus_greater_than_salary_count = df.filter(df.bonus > df.salary).count()\n",
    "print(\"Number of employees with a bonus greater than their salary:\", bonus_greater_than_salary_count)\n"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 2
   },
   "notebookName": "Databricks-Assignment1 (Basic Common Transformation)",
   "widgets": {}
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
